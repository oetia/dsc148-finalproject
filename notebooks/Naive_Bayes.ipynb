{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j4zcwLIJuG1O"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KDABJK5kuG1R"
   },
   "source": [
    "# Naive Bayes Classifier \n",
    "It is a conditional probability model, with formula: <br>\n",
    "$ P(C| x_1, x_2, x_3, ...) = \\frac{P(C)P(X|C)}{P(X)}$ <br>\n",
    "It is naive because we have naive assumption such that every pair of features are independent from each other given C.<br>\n",
    "So we can rewrite the formula as: <br>\n",
    "$ P(C| x_1, x_2, x_3, ...) = P(C)P(x_1|C)P(x_2|C)... = P(C)\\prod^{n}_{i=1} P(x_i|C)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_JUB-OvnuG1S"
   },
   "outputs": [],
   "source": [
    "class Naive_Bayes():\n",
    "    \"\"\"\n",
    "    \n",
    "    Naive Bayes classifer\n",
    "    \n",
    "    Attributes:\n",
    "        prior: P(Y)\n",
    "        likelihood: P(X_j | Y)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "            Some initializations, if neccesary\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model_name = 'Naive Bayes'\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train: np.array, y_train: np.array):\n",
    "        \n",
    "        \"\"\" \n",
    "            The fit function fits the Naive Bayes model based on the training data. \n",
    "            Here, we assume that all the features are **discrete** features. \n",
    "            \n",
    "            X_train is a matrix or 2-D numpy array, represnting training instances. \n",
    "            Each training instance is a feature vector. \n",
    "\n",
    "            y_train contains the corresponding labels. There might be multiple (i.e., > 2) classes.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 1. Modify and add some codes to the following for-loop\n",
    "                     to compute the correct prior distribution of all y labels.\n",
    "                  2. Make sure they are normalized to a distribution.\n",
    "        \"\"\"\n",
    "        \n",
    "        # might as well store for making prediction easier. this tag index system is kind of annoying and i would prefer to not have to parse that information out. \n",
    "        self.y_labels = np.unique(y_train)\n",
    "        # return self.y_labels\n",
    "        \n",
    "        self.y_counts = dict()\n",
    "        for value in y_train:\n",
    "            tag = f\"Y = {value}\"\n",
    "            self.y_counts[tag] = self.y_counts.get(tag, 0) + 1\n",
    "        self.prior = {k: v/len(y_train) for k, v in self.y_counts.items()}\n",
    "        # return self.prior\n",
    "            \n",
    "        \"\"\"\n",
    "            TODO: 3. Modify and add some codes to the following for-loops\n",
    "                     to compute the correct likelihood P(X_j | Y).\n",
    "                  4. Make sure they are normalized to distributions.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.likelihood = dict()\n",
    "        for x, y in zip(X_train, y_train):\n",
    "            x = np.array(x).reshape(-1) # taking the index of a matrix seems to force you to get back a matrix no matter what. \n",
    "            for j in range(len(x)):\n",
    "                tag = f\"X{j} = {x[j]} | Y = {y}\"\n",
    "                # self.likelihood[tag] = self.likelihood.get(tag, 0) + (1)\n",
    "                self.likelihood[tag] = self.likelihood.get(tag, 0) + (1/self.y_counts[f\"Y = {y}\"])\n",
    "                \n",
    "        return self.likelihood\n",
    "\n",
    "        \"\"\"\n",
    "            TODO: 5. Think about whether we really need P(X_1 = x_1, X_2 = x_2, ..., X_d = x_d)\n",
    "                     in practice?\n",
    "                  6. Does this really matter for the final classification results?\n",
    "        \"\"\"\n",
    "        \n",
    "        # no you don't. you can calculate that information on the fly when you need it. i suppose that if you have a ton of queries, it might be slightly more efficient to calculate those values beforehand. \n",
    "\n",
    "        \n",
    "    def ind_predict(self, x : list):\n",
    "        \n",
    "        \"\"\" \n",
    "            Predict the most likely class label of one test instance based on its feature vector x.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 7. Enumerate all possible class labels and compute the likelihood \n",
    "                     based on the given feature vector x. Don't forget to incorporate \n",
    "                     both the prior and likelihood.\n",
    "                  8. Pick the label with the higest probability. \n",
    "                  9. How to deal with very small probability values, especially\n",
    "                     when the feature vector is of a high dimension. (Hint: log)\n",
    "                  10. How to how to deal with unknown feature values?\n",
    "        \"\"\"\n",
    "        \n",
    "        # ok so we're going to be calculating log probs. log is a monotonically increasing function so we can just compare the log probs.\n",
    "        # if unkseen feature value across all just return 0 probability and no class. all logprobs will be -inf. leads to a tie, never setting ret. ret is returned as none. \n",
    "        \n",
    "        # ret, max_prob = None, 0\n",
    "        # for y in self.y_labels:\n",
    "        #     prob = 1\n",
    "        #     for index, value in enumerate(x):\n",
    "        #         tag = f\"X{index} = {value} | Y = {y}\"\n",
    "        #         prob *= self.likelihood.get(tag, 0) # no smoothing\n",
    "                \n",
    "        #     if prob > max_prob:\n",
    "        #         max_prob = prob\n",
    "        #         ret = y\n",
    "                    \n",
    "        # # print(ret)\n",
    "        # return ret\n",
    "        \n",
    "        ret, max_logprob = None, -np.inf\n",
    "        for y in self.y_labels:\n",
    "            logprob = np.log(self.prior[f\"Y = {y}\"])\n",
    "            for index, value in enumerate(x):\n",
    "                tag = f\"X{index} = {value} | Y = {y}\"\n",
    "                logprob += np.log(self.likelihood.get(tag, 0)) # no smoothing\n",
    "            \n",
    "            if logprob > max_logprob:\n",
    "                max_logprob = logprob\n",
    "                ret = y\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        print(X.shape)\n",
    "        \"\"\"\n",
    "            X is a matrix or 2-D numpy array, represnting testing instances. \n",
    "            Each testing instance is a feature vector. \n",
    "            \n",
    "            Return the predictions of all instances in a list.\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "            TODO: 11. Revise the following for-loop to call ind_predict to get predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        ret = []\n",
    "        for x in X:\n",
    "            ret.append(self.ind_predict(np.array(x).reshape(-1)))\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0g4b0OM7uG1U"
   },
   "outputs": [],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data'\n",
    "col = ['class_name','left_weight','left_distance','right_weight','right_distance']\n",
    "data = pd.read_csv(url, delimiter = ',', names = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hq7_a9C0uG1W",
    "outputId": "9f21f418-fa7d-4a77-dfc0-186ec3424e61"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>left_weight</th>\n",
       "      <th>left_distance</th>\n",
       "      <th>right_weight</th>\n",
       "      <th>right_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>L</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    class_name  left_weight  left_distance  right_weight  right_distance\n",
       "0            B            1              1             1               1\n",
       "1            R            1              1             1               2\n",
       "2            R            1              1             1               3\n",
       "3            R            1              1             1               4\n",
       "4            R            1              1             1               5\n",
       "..         ...          ...            ...           ...             ...\n",
       "620          L            5              5             5               1\n",
       "621          L            5              5             5               2\n",
       "622          L            5              5             5               3\n",
       "623          L            5              5             5               4\n",
       "624          B            5              5             5               5\n",
       "\n",
       "[625 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAsYzCPzuG1Z",
    "outputId": "60ec9f98-d513-479d-a6cf-e65d50d2d3c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "R    288\n",
       "L    288\n",
       "B     49\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.class_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JjkLsxGuG1e"
   },
   "outputs": [],
   "source": [
    "X = np.matrix(data.iloc[:,1:])\n",
    "y = data.class_name\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state = 88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_name\n",
       "L    202\n",
       "R    184\n",
       "B     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X0 = 1 | Y = R': 0.3695652173913047,\n",
       " 'X1 = 5 | Y = R': 0.0869565217391304,\n",
       " 'X2 = 2 | Y = R': 0.15760869565217384,\n",
       " 'X3 = 5 | Y = R': 0.3097826086956523,\n",
       " 'X1 = 3 | Y = R': 0.17934782608695643,\n",
       " 'X2 = 5 | Y = R': 0.331521739130435,\n",
       " 'X3 = 1 | Y = R': 0.05978260869565216,\n",
       " 'X0 = 3 | Y = L': 0.20792079207920802,\n",
       " 'X1 = 5 | Y = L': 0.32178217821782196,\n",
       " 'X2 = 1 | Y = L': 0.33168316831683187,\n",
       " 'X3 = 3 | Y = L': 0.18316831683168325,\n",
       " 'X0 = 5 | Y = L': 0.32178217821782196,\n",
       " 'X1 = 4 | Y = L': 0.2970297029702972,\n",
       " 'X2 = 5 | Y = L': 0.09900990099009903,\n",
       " 'X3 = 1 | Y = L': 0.34653465346534673,\n",
       " 'X0 = 3 | Y = R': 0.12499999999999994,\n",
       " 'X1 = 2 | Y = R': 0.2445652173913042,\n",
       " 'X2 = 4 | Y = R': 0.20652173913043467,\n",
       " 'X3 = 4 | Y = R': 0.26630434782608686,\n",
       " 'X0 = 5 | Y = R': 0.12499999999999994,\n",
       " 'X1 = 1 | Y = R': 0.347826086956522,\n",
       " 'X2 = 3 | Y = R': 0.23369565217391292,\n",
       " 'X0 = 4 | Y = L': 0.2722772277227724,\n",
       " 'X2 = 4 | Y = L': 0.1336633663366337,\n",
       " 'X3 = 4 | Y = L': 0.1435643564356436,\n",
       " 'X3 = 2 | Y = L': 0.22772277227722784,\n",
       " 'X0 = 4 | Y = R': 0.1304347826086956,\n",
       " 'X3 = 2 | Y = R': 0.1304347826086956,\n",
       " 'X0 = 2 | Y = L': 0.13861386138613865,\n",
       " 'X2 = 3 | Y = L': 0.17326732673267334,\n",
       " 'X0 = 5 | Y = B': 0.1875,\n",
       " 'X1 = 1 | Y = B': 0.21875,\n",
       " 'X2 = 1 | Y = B': 0.15625,\n",
       " 'X3 = 5 | Y = B': 0.15625,\n",
       " 'X3 = 3 | Y = R': 0.23369565217391292,\n",
       " 'X3 = 5 | Y = L': 0.09900990099009903,\n",
       " 'X1 = 2 | Y = L': 0.15841584158415847,\n",
       " 'X2 = 2 | Y = L': 0.2623762376237625,\n",
       " 'X1 = 4 | Y = R': 0.1413043478260869,\n",
       " 'X0 = 1 | Y = L': 0.059405940594059396,\n",
       " 'X0 = 3 | Y = B': 0.21875,\n",
       " 'X1 = 3 | Y = B': 0.1875,\n",
       " 'X2 = 3 | Y = B': 0.1875,\n",
       " 'X3 = 3 | Y = B': 0.21875,\n",
       " 'X2 = 1 | Y = R': 0.07065217391304346,\n",
       " 'X0 = 4 | Y = B': 0.21875,\n",
       " 'X1 = 2 | Y = B': 0.25,\n",
       " 'X2 = 4 | Y = B': 0.21875,\n",
       " 'X3 = 2 | Y = B': 0.25,\n",
       " 'X1 = 5 | Y = B': 0.125,\n",
       " 'X2 = 5 | Y = B': 0.15625,\n",
       " 'X0 = 2 | Y = R': 0.24999999999999986,\n",
       " 'X1 = 3 | Y = L': 0.1782178217821783,\n",
       " 'X3 = 1 | Y = B': 0.1875,\n",
       " 'X0 = 2 | Y = B': 0.21875,\n",
       " 'X1 = 1 | Y = L': 0.04455445544554455,\n",
       " 'X0 = 1 | Y = B': 0.15625,\n",
       " 'X2 = 2 | Y = B': 0.28125,\n",
       " 'X1 = 4 | Y = B': 0.21875,\n",
       " 'X3 = 4 | Y = B': 0.1875}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Naive_Bayes().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxU7v9SxuG1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X0 = 1 | Y = R': 0.3695652173913047,\n",
       " 'X1 = 5 | Y = R': 0.0869565217391304,\n",
       " 'X2 = 2 | Y = R': 0.15760869565217384,\n",
       " 'X3 = 5 | Y = R': 0.3097826086956523,\n",
       " 'X1 = 3 | Y = R': 0.17934782608695643,\n",
       " 'X2 = 5 | Y = R': 0.331521739130435,\n",
       " 'X3 = 1 | Y = R': 0.05978260869565216,\n",
       " 'X0 = 3 | Y = L': 0.20792079207920802,\n",
       " 'X1 = 5 | Y = L': 0.32178217821782196,\n",
       " 'X2 = 1 | Y = L': 0.33168316831683187,\n",
       " 'X3 = 3 | Y = L': 0.18316831683168325,\n",
       " 'X0 = 5 | Y = L': 0.32178217821782196,\n",
       " 'X1 = 4 | Y = L': 0.2970297029702972,\n",
       " 'X2 = 5 | Y = L': 0.09900990099009903,\n",
       " 'X3 = 1 | Y = L': 0.34653465346534673,\n",
       " 'X0 = 3 | Y = R': 0.12499999999999994,\n",
       " 'X1 = 2 | Y = R': 0.2445652173913042,\n",
       " 'X2 = 4 | Y = R': 0.20652173913043467,\n",
       " 'X3 = 4 | Y = R': 0.26630434782608686,\n",
       " 'X0 = 5 | Y = R': 0.12499999999999994,\n",
       " 'X1 = 1 | Y = R': 0.347826086956522,\n",
       " 'X2 = 3 | Y = R': 0.23369565217391292,\n",
       " 'X0 = 4 | Y = L': 0.2722772277227724,\n",
       " 'X2 = 4 | Y = L': 0.1336633663366337,\n",
       " 'X3 = 4 | Y = L': 0.1435643564356436,\n",
       " 'X3 = 2 | Y = L': 0.22772277227722784,\n",
       " 'X0 = 4 | Y = R': 0.1304347826086956,\n",
       " 'X3 = 2 | Y = R': 0.1304347826086956,\n",
       " 'X0 = 2 | Y = L': 0.13861386138613865,\n",
       " 'X2 = 3 | Y = L': 0.17326732673267334,\n",
       " 'X0 = 5 | Y = B': 0.1875,\n",
       " 'X1 = 1 | Y = B': 0.21875,\n",
       " 'X2 = 1 | Y = B': 0.15625,\n",
       " 'X3 = 5 | Y = B': 0.15625,\n",
       " 'X3 = 3 | Y = R': 0.23369565217391292,\n",
       " 'X3 = 5 | Y = L': 0.09900990099009903,\n",
       " 'X1 = 2 | Y = L': 0.15841584158415847,\n",
       " 'X2 = 2 | Y = L': 0.2623762376237625,\n",
       " 'X1 = 4 | Y = R': 0.1413043478260869,\n",
       " 'X0 = 1 | Y = L': 0.059405940594059396,\n",
       " 'X0 = 3 | Y = B': 0.21875,\n",
       " 'X1 = 3 | Y = B': 0.1875,\n",
       " 'X2 = 3 | Y = B': 0.1875,\n",
       " 'X3 = 3 | Y = B': 0.21875,\n",
       " 'X2 = 1 | Y = R': 0.07065217391304346,\n",
       " 'X0 = 4 | Y = B': 0.21875,\n",
       " 'X1 = 2 | Y = B': 0.25,\n",
       " 'X2 = 4 | Y = B': 0.21875,\n",
       " 'X3 = 2 | Y = B': 0.25,\n",
       " 'X1 = 5 | Y = B': 0.125,\n",
       " 'X2 = 5 | Y = B': 0.15625,\n",
       " 'X0 = 2 | Y = R': 0.24999999999999986,\n",
       " 'X1 = 3 | Y = L': 0.1782178217821783,\n",
       " 'X3 = 1 | Y = B': 0.1875,\n",
       " 'X0 = 2 | Y = B': 0.21875,\n",
       " 'X1 = 1 | Y = L': 0.04455445544554455,\n",
       " 'X0 = 1 | Y = B': 0.15625,\n",
       " 'X2 = 2 | Y = B': 0.28125,\n",
       " 'X1 = 4 | Y = B': 0.21875,\n",
       " 'X3 = 4 | Y = B': 0.1875}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Naive_Bayes()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 4)\n"
     ]
    }
   ],
   "source": [
    "y_test = np.array(y_test)\n",
    "y_hat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2RZ2jYsuG1h"
   },
   "source": [
    "Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpfumdTCuG1i",
    "outputId": "6925cbf8-873b-49f0-80b2-754f569c3f8b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8840579710144928"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_hat == y_test)/ 207  # you should get something like 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 2, 2, 1]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "0.07655502392344497\n",
      "0.15625\n",
      "0.25\n",
      "0.28125\n",
      "0.1875\n",
      "L\n",
      "0.48325358851674644\n",
      "0.059405940594059396\n",
      "0.15841584158415847\n",
      "0.2623762376237625\n",
      "0.34653465346534673\n",
      "R\n",
      "0.44019138755980863\n",
      "0.3695652173913047\n",
      "0.2445652173913042\n",
      "0.15760869565217384\n",
      "0.05978260869565216\n"
     ]
    }
   ],
   "source": [
    "# matrix([[1, 2, 2, 1]])\n",
    "for y_label in clf.y_labels:\n",
    "    print(y_label)\n",
    "    print(clf.prior.get(f\"Y = {y_label}\"))\n",
    "    print(clf.likelihood.get(f\"X0 = 1 | Y = {y_label}\"))\n",
    "    print(clf.likelihood.get(f\"X1 = 2 | Y = {y_label}\"))\n",
    "    print(clf.likelihood.get(f\"X2 = 2 | Y = {y_label}\"))\n",
    "    print(clf.likelihood.get(f\"X3 = 1 | Y = {y_label}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfZ9Mg4wuG1n"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "np.matrix is not supported. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CategoricalNB\n\u001b[1;32m      3\u001b[0m cnb \u001b[38;5;241m=\u001b[39m CategoricalNB()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcnb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m cnb_pred \u001b[38;5;241m=\u001b[39m cnb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28msum\u001b[39m(cnb_pred \u001b[38;5;241m==\u001b[39m y_test) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m207\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/naive_bayes.py:1378\u001b[0m, in \u001b[0;36mCategoricalNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m \n\u001b[1;32m   1356\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/naive_bayes.py:732\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    713\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \n\u001b[1;32m    715\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 732\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    735\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/naive_bayes.py:1436\u001b[0m, in \u001b[0;36mCategoricalNB._check_X_y\u001b[0;34m(self, X, y, reset)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1436\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1439\u001b[0m     check_non_negative(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCategoricalNB (input X)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/utils/validation.py:1263\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     )\n\u001b[0;32m-> 1263\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1281\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.2/lib/python3.11/site-packages/sklearn/utils/validation.py:833\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Input validation on an array, list, sparse matrix or similar.\u001b[39;00m\n\u001b[1;32m    735\u001b[0m \n\u001b[1;32m    736\u001b[0m \u001b[38;5;124;03mBy default, the input is checked to be a non-empty 2D array containing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;124;03marray([[1, 2, 3], [4, 5, 6]])\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, np\u001b[38;5;241m.\u001b[39mmatrix):\n\u001b[0;32m--> 833\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    834\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.matrix is not supported. Please convert to a numpy array with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    835\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.asarray. For more information see: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://numpy.org/doc/stable/reference/generated/numpy.matrix.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    837\u001b[0m     )\n\u001b[1;32m    839\u001b[0m xp, is_array_api_compliant \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    841\u001b[0m \u001b[38;5;66;03m# store reference to original array to check if copy is needed when\u001b[39;00m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# function returns\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: np.matrix is not supported. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html"
     ]
    }
   ],
   "source": [
    "# naives bayes sklearn\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "cnb_pred = cnb.predict(X_test)\n",
    "sum(cnb_pred == y_test) / 207"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "      <th>cnb_pred</th>\n",
       "      <th>y_hat == cnb_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>R</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>L</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  y_hat cnb_pred  y_hat == cnb_pred\n",
       "0     R        R               True\n",
       "1     L        L               True\n",
       "2     B        L              False\n",
       "3     B        R              False\n",
       "4     B        L              False"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe with columns: y_hat, cnb_pred, and y_hat == cnb_pred\n",
    "df = pd.DataFrame({'y_hat': y_hat, 'cnb_pred': cnb_pred, 'y_hat == cnb_pred': y_hat == cnb_pred})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'R'], dtype='<U1')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(cnb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'L', 'R'], dtype='<U1')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_hat)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "New_Naive_Bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
